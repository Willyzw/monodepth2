{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monodepth2_handson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNc1F2X6EZCljv1dludd5uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Willyzw/monodepth2/blob/master/monodepth2_handson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ28xSy7jzMB"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BblFpao5j2cy"
      },
      "source": [
        "Tracking the pose of a moving camera and simultanously inferring the **dense** structure of the environment is a long-standing problem sometimes denoted as **DenseSLAM**. Traditionally it is approached by two steps, namely a sparse set of feature points along with camera poses is firstly estimated, then followed by multi-view stereo(MVS) to construct the dense scene structure. While this traditional toolchain is well studied consisting of multiple elaborate hand-crafted stages, it lacks robustness in cases such as low texture, thin structure and dynamic objects. Besides that, modern applications like augmented reality or automated driving demand real-time dense scene perceiving for operations e.g. interaction between physical and virtual objects and obstacle avoidance.\r\n",
        "\r\n",
        "With the rapid development and recent advances of deep learning, there has been remarkable progress in this field in recent years. **MonoDepth2**[1] is one of the most representative works. It consists of a depth and a pose network to estimate depth map and camera pose respectively. More specifically, the pose network takes a pair of consecutive images $I_{t-1}$ and $I_t$ and outputs the relative transform from $I_{t-1}$ to $I_t$, while the depth network can map a RGB image $I_{t}$ though an encoder-decoder network to its corresponding depth map. This process can be illustrated as the figure below (Figure 1 of SfMLearner [3])  \r\n",
        "![](https://github.com/Willyzw/monodepth2/raw/master/assets/sfmlearner.png)\r\n",
        "\r\n",
        "This notebook aims to convey the MonoDepth2's principles by showing an example. Firstly the required development environment will be set up. Then, a few example images from KITTI dataset[4] are used to illustrated the process of image warping, which is the core principle for the self-supervised learning. At the end, we apply the pre-trained network model on a short video clip of Cityscapes dataset to check how the model generalizes to a different dataset.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cFnjqQ2t_Df"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptEdAGLPtxbh",
        "outputId": "7b0eb6c6-5dae-4394-cf7c-ecc3c8f71808"
      },
      "source": [
        "!git clone https://github.com/Willyzw/monodepth2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'monodepth2'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 165 (delta 4), reused 7 (delta 1), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (165/165), 13.30 MiB | 32.05 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qar5MnxBuDTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7478dc16-9505-4bbe-cf85-74037efce960"
      },
      "source": [
        "pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 2.4MB/s eta 0:07:49tcmalloc: large alloc 1147494400 bytes == 0x559046912000 @  0x7f8069ad5615 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb1ce50 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cc1d431 0x55900cb7e049 0x55900cae8c84 0x55900caa98e9 0x55900cb1dade 0x55900caaa69a 0x55900cb18a45 0x55900cb17e0d 0x55900caaa77a 0x55900cb18a45 0x55900caaa69a 0x55900cb18a45\n",
            "\u001b[K     |█████████████████               | 1055.7MB 38.1MB/s eta 0:00:25tcmalloc: large alloc 1434370048 bytes == 0x55908af68000 @  0x7f8069ad5615 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb1ce50 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cc1d431 0x55900cb7e049 0x55900cae8c84 0x55900caa98e9 0x55900cb1dade 0x55900caaa69a 0x55900cb18a45 0x55900cb17e0d 0x55900caaa77a 0x55900cb18a45 0x55900caaa69a 0x55900cb18a45\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.5MB/s eta 0:06:59tcmalloc: large alloc 1792966656 bytes == 0x55900fd9a000 @  0x7f8069ad5615 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb1ce50 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cc1d431 0x55900cb7e049 0x55900cae8c84 0x55900caa98e9 0x55900cb1dade 0x55900caaa69a 0x55900cb18a45 0x55900cb17e0d 0x55900caaa77a 0x55900cb18a45 0x55900caaa69a 0x55900cb18a45\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.3MB/s eta 0:03:43tcmalloc: large alloc 2241208320 bytes == 0x55907ab82000 @  0x7f8069ad5615 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb1ce50 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cb18ee2 0x55900cb9b7c6 0x55900cc1d431 0x55900cb7e049 0x55900cae8c84 0x55900caa98e9 0x55900cb1dade 0x55900caaa69a 0x55900cb18a45 0x55900cb17e0d 0x55900caaa77a 0x55900cb18a45 0x55900caaa69a 0x55900cb18a45\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.3MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x5591004e4000 @  0x7f8069ad41e7 0x55900cadc017 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900caaa69a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb17b0e\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x559176750000 @  0x7f8069ad5615 0x55900caa606c 0x55900cb85eba 0x55900caa8e8d 0x55900cb9a99d 0x55900cb1cfe9 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb18c9e 0x55900caaa69a 0x55900cb18c9e 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb17b0e 0x55900caaa77a 0x55900cb1986a 0x55900cb17b0e 0x55900caaae11\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 4.5kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 198kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed torch-1.8.0+cu111 torchvision-0.9.0+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eB1Tdt-uM9z"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKLNbPdKuQiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}